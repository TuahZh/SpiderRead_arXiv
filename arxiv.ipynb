{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from openpyxl import Workbook\n",
    "import random\n",
    "import pickle as pck\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reload(sys)\n",
    "#sys.setdefaultencoding('utf8')\n",
    "\n",
    "#Only for jupyter notebook\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_agent_list = [\n",
    "   #Chrome\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 5.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "    #Firefox\n",
    "    'Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n",
    "    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)',\n",
    "    'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Paper(object):\n",
    "    \"\"\"A paper object, containing some basic information of a paper, currently only arxiv papers\"\"\"\n",
    "    #self.nap_interval = 5. #sec\n",
    "    def __init__(self, arxiv_id=None, url=\"https://arxiv.org/abs/\", nap=5.):\n",
    "        self.nap_interval = nap\n",
    "        self.customized_fields = {}\n",
    "        self._url_prefix = url\n",
    "        if (arxiv_id is None):\n",
    "            self.title = \"\"\n",
    "            self.authors = []\n",
    "            self.arxiv_id = \"\"\n",
    "            self.link = \"\"\n",
    "            self.link_ads = \"\"\n",
    "            self.abstract = \"\"\n",
    "            self.date = \"\"\n",
    "            self.comments = \"\"\n",
    "            self.subjects = \"\"\n",
    "        else:\n",
    "            self._find_paper(arxiv_id, url)\n",
    "        \n",
    "    def _find_paper(self, arxiv_id, url):\n",
    "        \"\"\"Find a paper according to its arxiv id\"\"\"\n",
    "        self.arxiv_id = arxiv_id\n",
    "        self.link = url+arxiv_id\n",
    "        (self.title, self.authors, self.link_ads, \\\n",
    "            self.abstract, self.date, self.comments, self.subjects) = \\\n",
    "            self._read_page(arxiv_id, self.link, nap=self.nap_interval)\n",
    "        return\n",
    "    \n",
    "    @staticmethod\n",
    "    def _read_page(arxiv_id, url, nap=5.):\n",
    "        \"\"\"Read the page of an arxiv paper,\n",
    "        and return title, authors, the ads link, abstract\"\"\"\n",
    "        header = {'User-Agent':random.choice(user_agent_list)}\n",
    "        try:\n",
    "            source_code = requests.get(url, headers=header)\n",
    "            source_code.raise_for_status()\n",
    "        except HTTPError as e:\n",
    "            print(e)\n",
    "            return (\"\", [], \"\", \"\", \"\", \"\", \"\")\n",
    "        \n",
    "        plain_text = source_code.text\n",
    "        soup = BeautifulSoup(plain_text)\n",
    "\n",
    "#        title_str = str(soup.find(\"meta\", {\"name\":\"citation_title\"})).split(\"\\\"\")\n",
    "        # content is in the second place\n",
    "#        title = title_str[1]\n",
    "        title = soup.find(\"meta\", {\"name\":\"citation_title\"}).get(\"content\").strip()\n",
    "        #authors\n",
    "        #authors_str = str(soup.findAll(\"meta\", {\"name\":\"citation_author\"})).split(\"/\")\n",
    "        authors_list = []\n",
    "#        for cc in authors_str:\n",
    "#            if(cc.find(\"content\")!=-1):\n",
    "#                # content on the second index\n",
    "#                authors_list.append(cc.split(\"\\\"\")[1])\n",
    "#        print(authors_list)\n",
    "        for ss in soup.findAll(\"meta\", {\"name\":\"citation_author\"}):\n",
    "            authors_list.append(ss.get(\"content\").strip())\n",
    "                               \n",
    "        #print(soup.findAll(\"meta\", {\"name\":\"citation_author\"}).get(\"content\"))\n",
    "        ads_link = soup.find(\"a\", text=\"NASA ADS\").get('href').strip()\n",
    "\n",
    "        abstract = soup.find(\"meta\", {\"property\":\"og:description\"}).get(\"content\").strip()\n",
    "        date = soup.find(\"meta\", {\"name\":\"citation_date\"}).get(\"content\").strip()\n",
    "        comments = soup.find(\"td\", {\"class\":\"tablecell comments mathjax\"}).get_text().strip()\n",
    "        #subjects = [soup.find(\"span\",{\"class\":\"primary-subject\"}).get_text()]\n",
    "        subjects = soup.find(\"td\",{\"class\":\"tablecell subjects\"}).get_text().strip()\n",
    "        \n",
    "        time.sleep(random.random()*nap)\n",
    "        return (title, authors_list, ads_link, abstract, date, comments, subjects)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"<Paper id:%s link:%s>\" % (self.arxiv_id, self.link)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"ID: %s\\nTitle: %s\\nAuthors: %s\\nDate: %s\\nAbstract: %s\\nComments: %s\\nLink: %s\\nSubjects: %s\\n\" % \\\n",
    "            (self.arxiv_id, self.title, self._authors_in_line(), self.date, self.abstract, \\\n",
    "            self.comments, self.link, self.subjects)\n",
    "        \n",
    "    def _authors_in_line(self):\n",
    "        \"\"\"Return a single str of authors splitted with ; \"\"\"\n",
    "        s = \"\"\n",
    "        for cc in self.authors:\n",
    "            s += cc+\"; \"\n",
    "        return s[:-2]\n",
    "        \n",
    "    def search_online(self):\n",
    "        \"\"\"Search online according to the arxiv id\"\"\"\n",
    "        if(self.arxiv_id==\"\"):\n",
    "            print(\"The id is empty!\")\n",
    "            return 0\n",
    "        self._find_paper(self.arxiv_id, self._url_prefix)\n",
    "        return 1\n",
    "    \n",
    "    def customized_fields(self, key_name, value):\n",
    "        self.customized_fields[key_name] = value\n",
    "        \n",
    "    def fetch_pdf(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = Paper(arxiv_id=\"arXiv:1909.10883\")\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arxiv_reading(url=None, nap=5.):\n",
    "    \"\"\"Daily reading arxiv:\n",
    "    save to a pickle or something\"\"\"\n",
    "    if (url is None):\n",
    "        url = \"https://arxiv.org/list/astro-ph/new\"\n",
    "    header = {'User-Agent':random.choice(user_agent_list)}\n",
    "    source_code = requests.get(url, headers=header) \n",
    "    #time.sleep(np.random.rand()*10)\n",
    "    plain_text = source_code.text\n",
    "    soup = BeautifulSoup(plain_text)\n",
    "    time_str = soup.find(\"h3\").get_text().strip()\n",
    "    print(time_str)\n",
    "    paper_list = []\n",
    "    papers_sp = soup.find(\"dl\")\n",
    "    # =======================================================\n",
    "    # Only the new papars without cross list and replacements\n",
    "    # =======================================================\n",
    "    #paper_list = soup.find(\"div\", {'class': 'meta'})\n",
    "    item_list_sp = papers_sp.findAll(\"dt\")\n",
    "    paper_list_sp = papers_sp.findAll(\"dd\")\n",
    "    \n",
    "    if(len(item_list_sp)!=len(paper_list_sp)):\n",
    "        print(\"Warning: Length different!\")\n",
    "        \n",
    "    for tt, ss in zip(item_list_sp, paper_list_sp):\n",
    "        paper1 = Paper()\n",
    "        paper1.arxiv_id = tt.find(\"a\", {\"title\":\"Abstract\"}).get_text().strip()\n",
    "        title_sp = ss.find(\"div\", {\"class\":\"list-title mathjax\"})\n",
    "        title_sp.span.decompose()\n",
    "        paper1.title = title_sp.get_text().strip()\n",
    "        authors_sp = ss.find(\"div\", {\"class\":\"list-authors\"})\n",
    "        #authors_sp.span.decompose()\n",
    "        authors_list_sp = authors_sp.findAll(\"a\")\n",
    "        for au in authors_list_sp:\n",
    "            paper1.authors.append(au.get_text().strip())\n",
    "            \n",
    "        paper1.abstract = ss.find(\"p\", {\"class\":\"mathjax\"}).get_text().strip()\n",
    "        comments_sp = ss.find(\"div\", {\"class\":\"list-comments mathjax\"})\n",
    "        subjects_sp = ss.find(\"div\", {\"class\":\"list-subjects\"})\n",
    "        try:\n",
    "            comments_sp.span.decompose()\n",
    "            paper1.comments = comments_sp.get_text().strip()\n",
    "        except AttributeError as e:\n",
    "            pass\n",
    "        subjects_sp.span.decompose()\n",
    "        paper1.subjects = subjects_sp.get_text().strip()\n",
    "        paper1.date = time_str\n",
    "        #print(paper1)        \n",
    "        paper_list.append(paper1)\n",
    "\n",
    "    print(\"Sleep...\")\n",
    "    time.sleep(random.random()*nap)\n",
    "    print(\"Awake...\")\n",
    "    return paper_list, time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New submissions for Fri,  4 Oct 19\n",
      "Sleep...\n",
      "Awake...\n"
     ]
    }
   ],
   "source": [
    "pl, ts = arxiv_reading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ts.split(\",\")[-1].strip().replace(\" \", \"_\")+\"_paper_list.pkl\", \"w\") as f:\n",
    "    pck.dump(pl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "print(len(pl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListPapers(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if(len(args)==0):\n",
    "            self.list_paper=[]\n",
    "        elif(type(args[0]) is not list):\n",
    "            raise TypeError(\"A list of paper needed\")\n",
    "        else:\n",
    "            self.list_paper=args[0]\n",
    "        if(\"key_words\" in kwargs):\n",
    "            if (\"boost\" in kwargs):\n",
    "                self.add_key_words(kwargs[\"key_words\"], boost=kwargs[\"boost\"])\n",
    "            else:\n",
    "                self.add_key_words(kwargs[\"key_words\"], boost=1.)\n",
    "        if(\"exclude_key_words\" in kwargs):\n",
    "            self.exclude_key_words(kwargs[\"exclude_key_words\"])\n",
    "#        if(list_paper is None):\n",
    "#            self.list_paper = []\n",
    "#        else:\n",
    "#            self.list_paper = list_paper\n",
    "            \n",
    "    def __len__(self):\n",
    "        try:\n",
    "            return self.tot_num\n",
    "        except:\n",
    "            self.tot_num = len(self.list_paper)\n",
    "            return self.tot_num\n",
    "\n",
    "    def add_key_words(self, kw, boost=1.):\n",
    "        \"\"\"Add key words and calculate the sores in passing, key word contains upper case letter in the key_words\n",
    "        list. But all other dict keys are lower cases.\"\"\"\n",
    "        try:\n",
    "            self._boost\n",
    "        except AttributeError:\n",
    "            self._boost={}\n",
    "        if(type(kw) is list):\n",
    "            try:\n",
    "                self.key_words\n",
    "            except AttributeError:\n",
    "                self.key_words = []\n",
    "                \n",
    "            if(type(boost) is not list):\n",
    "                boost = [boost]*len(kw)\n",
    "            for kk, bb in zip(kw, boost):\n",
    "                # check if the key word already exist\n",
    "                pd = sum([1 for kkk in self.key_words if kkk.lower()==kk.lower()])\n",
    "                if (pd>0):\n",
    "                    print(\"This keyword is already in the database.\")\n",
    "                    continue\n",
    "                \n",
    "                self.key_words.append(kk.strip())\n",
    "                kk = kk.lower()\n",
    "                self._boost[kk] = bb\n",
    "                self.cal_key_word_scores(kk)\n",
    "                \n",
    "        elif(type(kw) is str):\n",
    "            try:\n",
    "                self.key_words\n",
    "            except AttributeError:\n",
    "                self.key_words = []\n",
    "                \n",
    "            # check if the key word already exist    \n",
    "            pd = sum([1 for kk in self.key_words if kk.lower()==kw.lower()])\n",
    "            if (pd>0):\n",
    "                print(\"This keyword is already in the database.\")\n",
    "                return\n",
    "            self.key_words.append(kw.strip())\n",
    "            kw = kw.lower()\n",
    "            self._boost[kw] = boost\n",
    "            self.cal_key_word_scores(kw)\n",
    "        else:\n",
    "            raise TypeError(\"A string or a list of string should be defined as key words!\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def del_key_word(self, kw):\n",
    "        \"\"\"Delete an existed key word, kw must be str\"\"\"\n",
    "        try:\n",
    "            for kk in self.key_words:\n",
    "                if(kw.strip().lower()==kk.strip().lower()):\n",
    "                    self.key_words.remove(kk)\n",
    "                    kk = kk.strip().lower()\n",
    "                    self._boost.pop(kk, None)\n",
    "                    self.scores.pop(kk, None)\n",
    "                    self._update_tot_scores()\n",
    "                    pass\n",
    "                    return\n",
    "        except AttributeError:\n",
    "            print(\"An error occured when deleting a key word. The list of key words not defined.\")\n",
    "            return\n",
    "        print(\"Murmur: key word not exist.\")\n",
    "        return\n",
    "    \n",
    "    def exclude_key_words(self, kw):\n",
    "        \"\"\"Exclude the kw when scoring the files.\"\"\"\n",
    "        if(type(kw) is str):\n",
    "            try:\n",
    "                self.exclude_kws.append(kw.strip())\n",
    "            except AttributeError:\n",
    "                self.exclude_kws = [kw.strip()]\n",
    "            kw = kw.strip().lower()\n",
    "            self.cal_key_word_scores(kw, exclude=True)\n",
    "        elif(type(kw) is list):\n",
    "            try:\n",
    "                self.exclude_kws.extend([kk.strip() for kk in kw])\n",
    "            except AttributeError:\n",
    "                self.exclude_kws = [kk.strip() for kk in kw]\n",
    "            for kk in kw:\n",
    "                kk = kk.strip().lower()\n",
    "                self.cal_key_word_scores(kk, exclude=True)\n",
    "        else:\n",
    "            raise TypeError(\"A string or a list of string should be defined as key words!\")\n",
    "        self._update_tot_scores()\n",
    "        return\n",
    "    \n",
    "    def reset_exclude(self):\n",
    "        \"\"\"Delete all excluded key words\"\"\"\n",
    "        try:\n",
    "            del self.exclude_kws\n",
    "            # The scores dict contains excluding information, but will not be used\n",
    "            self._update_tot_scores()\n",
    "        except AttributeError:\n",
    "            print(\"Murmur: no key word excluded\")\n",
    "        return \n",
    "    \n",
    "    def cal_key_word_scores(self, kw, exclude=False):\n",
    "        \"\"\"Calculate the key word scores, kw must be str\n",
    "        Lucene method\"\"\"\n",
    "        self.tot_num = len(self.list_paper)\n",
    "        kw = kw.lower()\n",
    "        try:\n",
    "            self.scores[kw] = [0.]*self.tot_num\n",
    "        except AttributeError:\n",
    "            self.scores = {}\n",
    "            self.scores[kw] = [0.]*self.tot_num\n",
    "        if(exclude):\n",
    "            for ii in range(self.tot_num):\n",
    "                if(self._kw_match(self.list_paper[ii], kw)):\n",
    "                    self.scores[kw][ii] = -1\n",
    "        else:\n",
    "            for ii in range(self.tot_num):\n",
    "                self.scores[kw][ii] = self._idf(self._kw_n(kw), self.tot_num)* \\\n",
    "                                self._boost[kw]*self._tfnorm(kw, self.list_paper[ii], self.aver_length())\n",
    "                \n",
    "        self._update_tot_scores()\n",
    "        return self.scores[kw]\n",
    "    \n",
    "    def _update_tot_scores(self):\n",
    "\n",
    "        self.tot_scores = [0.]*self.tot_num\n",
    "        for ii in range(self.tot_num):\n",
    "            for kw in self.key_words:\n",
    "                self.tot_scores[ii] += self.scores[kw.lower()][ii]\n",
    "        try:\n",
    "            self.exclude_kws\n",
    "            for ii in range(self.tot_num):\n",
    "                for kw in self.exclude_kws:\n",
    "                    self.tot_scores[ii] *= self.scores[kw.lower()][ii]+1\n",
    "        except AttributeError:\n",
    "            pass\n",
    "                \n",
    "            \n",
    "        return\n",
    "            \n",
    "    def _kw_match(self, pp, kw):\n",
    "        \"\"\"Return if the kw is in the pp paper\"\"\"\n",
    "        kw = kw.strip().lower()\n",
    "        if(pp.title.lower().find(kw)!=-1 or pp.abstract.lower().find(kw)!=-1):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def _kw_n(self, kw):\n",
    "        \"\"\"Count the keywords documents\"\"\"\n",
    "        return len(self.search_keyword(kw))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _idf(kw_n, doc_n):\n",
    "        \"\"\"Inverse Document Frequency (IDF) function\"\"\"\n",
    "        return np.log(1.+(float(doc_n)-float(kw_n)+0.5)/(float(kw_n)+0.5))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _tfnorm(kw, pp, aver_length):\n",
    "        \"\"\"Normalized term frequency for a paper pp.\n",
    "        Should title be weighted more than the abstract?\"\"\"\n",
    "        tf = float(sum(1 for _ in re.finditer(kw, pp.title.lower()))+ \\\n",
    "            sum(1 for _ in re.finditer(kw, pp.abstract.lower())))\n",
    "        k1 = 1.2 # term frequency saturation\n",
    "        b = 0.75 # normlizaion of doc length\n",
    "        len_doc = float(len(pp.title.strip().split())+len(pp.abstract.strip().split()))\n",
    "        if (len_doc<=0.):\n",
    "            print(\"Warning: paper is empty!\")\n",
    "        return tf*(k1+1.)/(tf+k1*(1.-b+b*len_doc/aver_length))\n",
    "        #self.aver_length()\n",
    "        \n",
    "    def aver_length(self):\n",
    "        \"\"\"average the total length of papers\"\"\"\n",
    "        try:\n",
    "            return float(sum(len(pp.title.strip().split())+len(pp.abstract.strip().split()) \\\n",
    "                       for pp in self.list_paper))/float(self.tot_num)\n",
    "        except AttributeError:\n",
    "            return float(sum(len(pp.title.strip().split())+len(pp.abstract.strip().split()) \\\n",
    "                       for pp in self.list_paper))/float(len(self.list_paper))\n",
    "    \n",
    "    def search_keyword(self, kw):\n",
    "        \"\"\"Search the docs that contains keyword 'kw'.\n",
    "        Return a list. Maybe return a ListPaper in future.\"\"\"\n",
    "        kw = kw.lower()\n",
    "        searched_list = []\n",
    "        for pp in self.list_paper:\n",
    "            if(pp.title.lower().find(kw)!=-1 or pp.abstract.lower().find(kw)!=-1):\n",
    "                searched_list.append(pp)\n",
    "        return searched_list\n",
    "    \n",
    "    def head(self, n=3, score=True, sync=False, fetch=False):\n",
    "        \"\"\"Show the first n papers on the list according to total scores or not\"\"\"\n",
    "        if(score):\n",
    "            argsort_score = np.argsort(-np.array(self.tot_scores))\n",
    "            for ii in range(n):\n",
    "                if(sync):\n",
    "                    self.list_paper[argsort_score[ii]].search_online()\n",
    "                print(self.list_paper[argsort_score[ii]])\n",
    "        else:\n",
    "            for ii in range(n):\n",
    "                if(sync):\n",
    "                    self.list_paper[argsort_score[ii]].search_online()\n",
    "                print(self.list_paper[ii])\n",
    "                \n",
    "        return\n",
    "    \n",
    "    def filter_subjects(self, subj):\n",
    "        \"\"\"Make a new list with the subjects in subj\"\"\"\n",
    "        if(type(subj) is str):\n",
    "            subj = [subj]\n",
    "        new_list = list([pp for pp in self.list_paper if self._subj_contain(pp, subj)])\n",
    "        #print(len(new_list))\n",
    "        try:\n",
    "            return ListPapers(new_list, key_words=self.key_words, exclude_key_words=self.exclude_key_words)\n",
    "        except:\n",
    "            try:\n",
    "                return ListPapers(new_list, key_words=self.key_words)\n",
    "            except AttributeError:\n",
    "                return ListPapers(new_list)\n",
    "        raise \n",
    "    \n",
    "    def _subj_contain(self, pp, subj):\n",
    "        \"\"\"Return True if a paper pp contains any of subj as subjects\"\"\"\n",
    "        # subj is a list\n",
    "        for ss in subj:\n",
    "            if (pp.subjects.find(ss)!=-1):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def all_subjects(self):\n",
    "        \"\"\"Show all the subjects of the list\"\"\"\n",
    "        try:\n",
    "            self.subjects_list\n",
    "        except AttributeError:\n",
    "            self.subjects_list = []\n",
    "        for pp in self.list_paper:\n",
    "            subj = [cc.strip() for cc in pp.subjects.split(\";\")]\n",
    "            for ss in subj:\n",
    "                if (ss not in self.subjects_list):\n",
    "                    self.subjects_list.append(ss)\n",
    "        return self.subjects_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_c = ListPapers(pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Astrophysics of Galaxies (astro-ph.GA)',\n",
       " u'Cosmology and Nongalactic Astrophysics (astro-ph.CO)',\n",
       " u'Solar and Stellar Astrophysics (astro-ph.SR)',\n",
       " u'Earth and Planetary Astrophysics (astro-ph.EP)',\n",
       " u'Instrumentation and Methods for Astrophysics (astro-ph.IM)',\n",
       " u'High Energy Astrophysical Phenomena (astro-ph.HE)',\n",
       " u'High Energy Physics - Theory (hep-th)',\n",
       " u'Nuclear Theory (nucl-th)',\n",
       " u'Space Physics (physics.space-ph)',\n",
       " u'General Relativity and Quantum Cosmology (gr-qc)']"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_c.all_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_c.add_key_words([\"chemistry\",\"Galactic center\",\"SNR\"])\n",
    "#lp_c.del_key_word(\"Chemistry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3168297931300303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.89014580842331, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.1505873268185747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "['chemistry', 'Galactic center', 'SNR']\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3168297931300303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(lp_c.tot_scores)\n",
    "print(lp_c.key_words)\n",
    "print(lp_c.scores[\"galactic center\"])\n",
    "print(lp_c.scores[\"snr\"])\n",
    "#print(lp_c.scores[\"chemistry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, -1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1, 0.0, 0.0, -1, -1, 0.0, 0.0, -1, 0.0, 0.0, 0.0, 0.0, 0.0, -1, 0.0, 0.0, -1, 0.0, 0.0, -1, -1, 0.0, 0.0, -1, 0.0, 0.0, -1, 0.0, 0.0, -1, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3168297931300303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.89014580842331, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, -1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1, 0.0, 0.0, -1, -1, 0.0, 0.0, -1, 0.0, 0.0, 0.0, 0.0, 0.0, -1, 0.0, 0.0, -1, 0.0, 0.0, -1, -1, 0.0, 0.0, -1, 0.0, 0.0, -1, 0.0, 0.0, -1, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3168297931300303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.89014580842331, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.1505873268185747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "lp_c.exclude_key_words(\"planet\")\n",
    "print(lp_c.scores[\"planet\"])\n",
    "print(lp_c.tot_scores)\n",
    "lp_c.reset_exclude()\n",
    "print(lp_c.scores[\"planet\"])\n",
    "print(lp_c.tot_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_d=lp_c.filter_subjects(\"astro-ph.CO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chemistry', 'Galactic center', 'SNR']\n"
     ]
    }
   ],
   "source": [
    "print(lp_d.key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: arXiv:1910.01554\n",
      "Title: The role of C/O in nitrile astrochemistry in PDRs and planet-forming disks\n",
      "Authors: Gal, Romane Le; Brady, Madison T.; Öberg, Karin I.; Roueff, Evelyne; Petit, Franck Le\n",
      "Date: 2019/10/03\n",
      "Abstract: Complex nitriles, such as HC3N, and CH3CN, are observed in a wide variety of\n",
      "astrophysical environments, including at relatively high abundances in\n",
      "photon-dominated regions (PDR) and the UV exposed atmospheres of planet-forming\n",
      "disks. The latter have been inferred to be oxygen-poor, suggesting that these\n",
      "observations may be explained by organic chemistry in C-rich environments. In\n",
      "this study we first explore if the PDR complex nitrile observations can be\n",
      "explained by gas-phase PDR chemistry alone if the elemental C/O ratio is\n",
      "elevated. In the case of the Horsehead PDR, we find that gas-phase chemistry\n",
      "with C/O $\\gtrsim$ 0.9 can indeed explain the observed nitrile abundances,\n",
      "increasing predicted abundances by several orders of magnitude compared to\n",
      "standard C/O assumptions. We also find that the nitrile abundances are\n",
      "sensitive to the cosmic ray ionization treatment, and provide constraints on\n",
      "the branching ratios between CH3CN and CH3NC productions. In a fiducial disk\n",
      "model, an elevated C/O ratio increases the CH3CN and HC3N productions by more\n",
      "than an order of magnitude, bringing abundance predictions within an order of\n",
      "magnitude to what has been inferred from observations. The C/O ratio appears to\n",
      "be a key variable in predicting and interpreting complex organic molecule\n",
      "abundances in photon-dominated regions across a range of scales.\n",
      "Comments: 15 pages, 7 figures, 2 tables, accepted for publication in ApJ\n",
      "Link: https://arxiv.org/abs/arXiv:1910.01554\n",
      "Subjects: Earth and Planetary Astrophysics (astro-ph.EP); Astrophysics of Galaxies (astro-ph.GA); Solar and Stellar Astrophysics (astro-ph.SR)\n",
      "\n",
      "ID: arXiv:1910.01261\n",
      "Title: Positive Ion Chemistry in an N$_2$-CH$_4$ Plasma Discharge: Key Precursors to the Growth of Titan Tholins\n",
      "Authors: Dubois, David; Carrasco, Nathalie; Jovanovic, Lora; Vettier, Ludovic; Gautier, Thomas; Westlake, Joseph\n",
      "Date: 2019/10/03\n",
      "Abstract: Titan is unique in the solar system as it hosts a dense atmosphere mainly\n",
      "made of N$_2$ and CH$_4$. Cassini-Huygens revealed the presence of an intense\n",
      "atmospheric photochemistry initiated by the photo-dissociation and ionization\n",
      "of N$_2$ and CH$_4$. In the upper atmosphere, Cassini detected signatures\n",
      "compatible with the presence of heavily charged molecules, precursors for the\n",
      "solid core of the aerosols. However, the processes coupling ion chemistry and\n",
      "aerosol formation and growth are still mostly unknown. In this study, we\n",
      "investigated the cation chemistry responsible for an efficient organic growth\n",
      "that we observe in Titan's upper atmosphere, simulated using the PAMPRE plasma\n",
      "reactor. Cation precursors were measured by in situ ion mass spectrometry in a\n",
      "cold plasma and compared with INMS observations taken during the T40 flyby. A\n",
      "series of positive ion measurements were performed in three CH$_4$ mixing\n",
      "ratios (1%, 5% and 10%) showing a variability in ion population. Low CH$_4$\n",
      "concentrations result in an abundance of amine cations such as NH$_4^+$ whereas\n",
      "aliphatic compounds dominate at higher methane concentrations. In conditions of\n",
      "favored tholin production, the presence of C2 compounds such as HCNH$^+$ and\n",
      "C$_2$H$_5^+$ is found to be consistent with copolymeric growth structures seen\n",
      "in tholin material. The observed abundance of these two ions particularly in\n",
      "conditions with lower CH$_4$ amounts is consistent with modeling work\n",
      "simulating aerosol growth in Titan's ionosphere, which includes mass exchange\n",
      "primarily between HCNH$^+$ and C$_2$H$_5^+$ and negatively charged particles.\n",
      "These results also confirm the prevalent role of C2 cations as precursors to\n",
      "molecular growth and subsequent mass transfer to the charged aerosol particles\n",
      "as the CH$_4$ abundance decreases towards lower altitudes.\n",
      "Comments: 39 pages, 20 figures, 3 tables, Accepted for publication in Icarus (abstract shortened)\n",
      "Link: https://arxiv.org/abs/arXiv:1910.01261\n",
      "Subjects: Earth and Planetary Astrophysics (astro-ph.EP)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp_c.head(sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pl_nap(time):\n",
    "    \"\"\"power law nap time\"\"\"\n",
    "    a = 1.\n",
    "    b = 0.75\n",
    "    return a*time**b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11b962190>]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEGCAYAAACEgjUUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11baf78d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(arange(50)/49.*86400./60./60., pl_nap(arange(50)/49.*86400.)/60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = Paper(arxiv_id=\"1909.12305\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Supersonic',\n",
       " 'turbulence',\n",
       " 'results',\n",
       " 'in',\n",
       " 'strong',\n",
       " 'density',\n",
       " 'fluctuations',\n",
       " 'in',\n",
       " 'the',\n",
       " 'interstellar',\n",
       " 'medium',\n",
       " '(ISM),',\n",
       " 'which',\n",
       " 'have',\n",
       " 'a',\n",
       " 'profound',\n",
       " 'effect',\n",
       " 'on',\n",
       " 'the',\n",
       " 'chemical',\n",
       " 'structure.',\n",
       " 'Particularly',\n",
       " 'useful',\n",
       " 'probes',\n",
       " 'of',\n",
       " 'the',\n",
       " 'diffuse',\n",
       " 'ISM',\n",
       " 'are',\n",
       " 'the',\n",
       " 'ArH$^+$,',\n",
       " 'OH$^+$,',\n",
       " 'H$_2$O$^+$',\n",
       " 'molecular',\n",
       " 'ions,',\n",
       " 'which',\n",
       " 'are',\n",
       " 'highly',\n",
       " 'sensitive',\n",
       " 'to',\n",
       " 'fluctuations',\n",
       " 'in',\n",
       " 'the',\n",
       " 'density',\n",
       " 'and',\n",
       " 'the',\n",
       " 'H$_2$',\n",
       " 'abundance.',\n",
       " 'We',\n",
       " 'use',\n",
       " 'isothermal',\n",
       " 'magnetohydrodynamic',\n",
       " '(MHD)',\n",
       " 'simulations',\n",
       " 'of',\n",
       " 'various',\n",
       " 'sonic',\n",
       " 'Mach',\n",
       " 'numbers,',\n",
       " '$\\\\mathcal{M}_s$,',\n",
       " 'and',\n",
       " 'density',\n",
       " 'decorrelation',\n",
       " 'scales,',\n",
       " '$y_{\\\\rm',\n",
       " 'dec}$,',\n",
       " 'to',\n",
       " 'model',\n",
       " 'the',\n",
       " 'turbulent',\n",
       " 'density',\n",
       " 'field.',\n",
       " 'We',\n",
       " 'post-process',\n",
       " 'the',\n",
       " 'simulations',\n",
       " 'with',\n",
       " 'chemical',\n",
       " 'models',\n",
       " 'and',\n",
       " 'obtain',\n",
       " 'the',\n",
       " 'probability',\n",
       " 'density',\n",
       " 'functions',\n",
       " '(PDFs)',\n",
       " 'for',\n",
       " 'the',\n",
       " 'H$_2$,',\n",
       " 'ArH$^+$,',\n",
       " 'OH$^+$',\n",
       " 'and',\n",
       " 'H$_2$O$^+$',\n",
       " 'abundances.',\n",
       " 'We',\n",
       " 'find',\n",
       " 'that',\n",
       " 'the',\n",
       " 'PDF',\n",
       " 'dispersions',\n",
       " 'increases',\n",
       " 'with',\n",
       " 'increasing',\n",
       " '$\\\\mathcal{M}_s$',\n",
       " 'and',\n",
       " '$y_{\\\\rm',\n",
       " 'dec}$,',\n",
       " 'as',\n",
       " 'the',\n",
       " 'magnitude',\n",
       " 'of',\n",
       " 'the',\n",
       " 'density',\n",
       " 'fluctuations',\n",
       " 'increases,',\n",
       " 'and',\n",
       " 'as',\n",
       " 'they',\n",
       " 'become',\n",
       " 'more',\n",
       " 'coherent.',\n",
       " 'Turbulence',\n",
       " 'also',\n",
       " 'affects',\n",
       " 'the',\n",
       " 'median',\n",
       " 'abundances:',\n",
       " 'when',\n",
       " '$\\\\mathcal{M}_s$',\n",
       " 'and',\n",
       " '$y_{\\\\rm',\n",
       " 'dec}$',\n",
       " 'are',\n",
       " 'high,',\n",
       " 'low-density',\n",
       " 'regions',\n",
       " 'with',\n",
       " 'low',\n",
       " 'H$_2$',\n",
       " 'abundance',\n",
       " 'become',\n",
       " 'prevalent,',\n",
       " 'resulting',\n",
       " 'in',\n",
       " 'an',\n",
       " 'enhancement',\n",
       " 'of',\n",
       " 'ArH$^+$',\n",
       " 'compared',\n",
       " 'to',\n",
       " 'OH$^+$',\n",
       " 'and',\n",
       " 'H$_2$O$^+$.',\n",
       " 'We',\n",
       " 'compare',\n",
       " 'our',\n",
       " 'models',\n",
       " 'with',\n",
       " 'Herschel',\n",
       " 'observations.',\n",
       " 'The',\n",
       " 'large',\n",
       " 'scatter',\n",
       " 'in',\n",
       " 'the',\n",
       " 'observed',\n",
       " 'abundances,',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'the',\n",
       " 'high',\n",
       " 'observed',\n",
       " 'ArH$^+$/OH$^+$',\n",
       " 'and',\n",
       " 'ArH$^+$/H$_2$O$^+$',\n",
       " 'ratios',\n",
       " 'are',\n",
       " 'naturally',\n",
       " 'reproduced',\n",
       " 'by',\n",
       " 'our',\n",
       " 'supersonic',\n",
       " '$(\\\\mathcal{M}_s=4.5)$,',\n",
       " 'large',\n",
       " 'decorrelation',\n",
       " 'scale',\n",
       " '$(y_{\\\\rm',\n",
       " 'dec}=0.8)$',\n",
       " 'model,',\n",
       " 'supporting',\n",
       " 'a',\n",
       " 'scenario',\n",
       " 'of',\n",
       " 'a',\n",
       " 'large-scale',\n",
       " 'turbulence',\n",
       " 'driving.',\n",
       " 'The',\n",
       " 'abundances',\n",
       " 'also',\n",
       " 'depend',\n",
       " 'on',\n",
       " 'the',\n",
       " 'UV',\n",
       " 'intensity,',\n",
       " 'CR',\n",
       " 'ionization',\n",
       " 'rate,',\n",
       " 'and',\n",
       " 'the',\n",
       " 'cloud',\n",
       " 'column',\n",
       " 'density,',\n",
       " 'and',\n",
       " 'the',\n",
       " 'observed',\n",
       " 'scatter',\n",
       " 'may',\n",
       " 'be',\n",
       " 'influenced',\n",
       " 'by',\n",
       " 'fluctuations',\n",
       " 'in',\n",
       " 'these',\n",
       " 'parameters.']"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = pp.abstract.split()\n",
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(*arg, **argv):\n",
    "    print(len(arg))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "foo([\"a\", \"b\"], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 5]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,3,4,5]\n",
    "b = [2,3,4,6]\n",
    "[ii for ii in a if (ii==bb for bb in b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
